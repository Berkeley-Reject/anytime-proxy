# Beyond Classical Search

## Local search algorithms

Local search algorithms operate with a single current node and move to neighbors to the node and the paths followed by the saerch are not retained. The memory usage is constant and reasonable solutions could be found in infinite state spaces. The algorithms could also solve pure optimization problems to find the best state based on an objective function.

The **elevation** is the value of the heuristic cost function or objective function based on the **location**. The algorithm is complete if it finds a goal if it exists, and is optimal if it finds a global maximum or minimum.

### Hill-climbing search

The hill-climbing search algorithm is a loop that moves in the direction of increasing value and terminates when it reaches a peak where no neighbor has a higher value. It doesn't look beyond the immediate neighbors of the current state. The algorithm could reach a local maxima, ridge, or plateaux where no process is being made. The random-restart hill climbing conducts a series of hill-climbing searches from random initial states until a goal is found.

### Simulated annealing

The simulated annealing algorithm is a loop that picks a random move for each state. If the move doesn't improve the situation, it's accepted with some probability less than $1$. The probability decreases exponentially when the badness of the move $\Delta E$ and as the temperature $T$ goes down. The algorithm is optimal and complete if the scheduler lowers $T$ slowly enough.

### Local beam search

The local bean search algorithm keeps track of $k$ states rather than one. The algorithm begins with $k$ randomly generated states. At each step, all the successors of all $k$ states are generated, and it selects the $k$ best successors from the complete list until it finds a goal. The stochastic bean search algorithm selects $k$ random successors with the probability of choosing a given successor being an increasing function of its value.

### Genetic algorithm

The genetic algorithm is a variant of stochastic beam search in which successor states are generated by combining two parent states rather than modifying a single state.

1. The algorithm selects the **population**, a set of $k$ randomly generated states. Each state is represented as a string over a finite alphabet.
2. The algorithm rates each state based on the objective function (fitness function), which should return higher values for better states. The probability of being choose for reproducing is porportional to the fitness score.
3. The algorithm selects $k / 2$ pairs for reproduction based on the probability. Each pair to be mated creates the offspring by crossing over their strings at a random crossover point. The crossover takes large steps in the state space early in the search process and smaller steps later on when most individuals are similar.
4. Each location of the offsprings is subject to random mutation with a small independent probability.
